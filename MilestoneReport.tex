
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font than Computer Modern for most use cases
    \usepackage{palatino}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    \title{Springboard Capstone Project: Milestone Report}
\author{DP Rooney}

\date{August 11, 2016}
    
    
    \maketitle
    
    

    


    \section{Introduction and
Background}\label{introduction-and-background}

There has been considerable growth in advanced statistics for
professional hockey in the last few years. Traditionally, shots on goal
has been an important statistic, but this has expanded to consider
Fenwick stats (shots on goal + shots missed) and Corsi stats (shots on
goal + shots missed + shots blocked). Corsi stats are also called shot
attempts. Additionally, instead of looking at the shot the player
himself attempts, one considers the on-ice statistics: the shot
attempts that occur when he is on the ice, both for his team, and
against his team. One can define the ``Corsi-for percentage'', or CF\%,
as follows:

\[\textrm{ CF\%(player X) } = \frac{\textrm{No. shot attempts for X's team | X on-ice}}{\textrm{No. shot attempts for both teams | X on-ice }} \]

\noindent This stat evaluates how a player contributes to producing shot attempts
for his team while preventing shot attempts against his team. Some of
the attractive features of this statistic are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  It combines offensive and defensive merit, so that players with flashy
  scoring and frequent defensive lapses are not over-rated.
\item
  It credits players that contribute indirectly to an offensive play,
  such as with canny passes from the defensive zone, tight
  fore-checking, and smart spacing.
\item
  It eliminates some of the randomness inherent to turning shot attempts
  into goals.
\item
  The data set is larger (there are around twice as many shot attempts per game
  as shots on goal).
\end{enumerate}

One major drawback with this stat is that it does not take into account
the quality of opposition. A fundamental phenomenon in hockey is
line-matching. Each team has four different forward-lines (and three
defense-pairings) that generally differ in abilities, and coaches will
strategize as how to optimize the match-ups between opposing lines. For
example, a good defensive forward line will often be matched against the
opposition's best offensive line. Therefore, comparing the CF\% of a
first-line and a fourth-line player is unfair to the better player,
since he has to work harder to generate a shot attempt, and prevent
opposing shot attempts.

For example, the reddit post below points out that Jake Virtanen, a young,
raw prospect for the Vancouver Canucks, has a better CF\% than Jonathan
Toews, who is seen as one of the best players in the league:

\url{https://www.reddit.com/r/canucks/comments/4omaqp/why\_jake\_virtanen\_is\_better\_than\_jonathan\_toews/}

\noindent While Virtanen may develop into one of the best players in the league,
it is unlikely that his performance was on par with Toews' last season.

The goal of my project is to develop a model that is more nuanced.
Instead of modeling the ratio of shot-attempts as a function of a single
player, we will consider the probability of shot-attempts as a function
of all players on the ice. In other words, we want to model the
probability
\
\[P(\textrm{ next SA is for home-team } | \textrm{ home-players } X_1, … X_6 \textrm{ on-ice; away-players } Y_1, …, Y_6 \textrm{ on-ice } )\]

My prospective client would be the management of a hockey team that
wants to evaluate players in ways that go past the common wisdom. It may
want to track the performance of its own players, and also evaluate
players that are becoming free agents in the off-season. A predictive
model that describes shot-attempt probability relative to opposing
players would allow a team to directly compare players and assess their
relative value.

    \section{Scraping and Wrangling}\label{scraping-and-wrangling}

The data for this project was scraped from three types of game reports from the NHL: game
rosters, event summaries and play-by-play reports. The URL's for the
first game are here:

\url{http://www.nhl.com/scores/htmlreports/20152106/RO020001.HTM}

\url{http://www.nhl.com/scores/htmlreports/20152106/ES020001.HTM}

\url{http://www.nhl.com/scores/htmlreports/20152106/PL020001.HTM}

The two-letter codes RO, ES and PL indicate the report type, and the
last four digits of the six-digit sequences indicate the game number (the first two
digits distinguish pre-season (01), regular season (02) and post-season
(03)). There were 1230 game in the 2015-2016 regular season (30 teams and
82 games each). These reports are all in pure HTML (no CSS or JSON), so
I had to go through a lot of nested
\texttt{\textless{}table\textgreater{}}'s to get the necessary data.

My Python code for scraping this data falls into six files:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{os}                
        \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scraping}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

            \begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}1}]:} ['report\_downloader.py',
         'directory\_build.py',
         'roster\_scrape.py',
         '.ipynb\_checkpoints',
         'attempt\_scrape.py',
         'salary\_fill.py',
         'es\_scrape.py']
\end{Verbatim}
        
    An overview of the code in these files:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The file \texttt{roster\_scrape.py} contains code for scraping the
  roster reports. It includes a class \texttt{RosterParse} which
  extracts the forty players that dressed (eighteen players and two
  goalies for each team). This includes their team, the player name, the
  position (center, left wing, right wing, defense or goalie) and their
  jersey number. A second class, \texttt{RosterBuilder} assembled
  rosters for all 1230 games and saved them in a 49,200 line file
  \texttt{Big\_Roster.csv}.
\item
  The file \texttt{directory\_build.py} contains code for consolidating
  the big roster into a player directory. It includes a class
  \texttt{SalaryParse} that extracts the salary for each player from the
  web-site \url{www.capfriendly.com}. The class \texttt{DirectoryBuilder}
  constructs the player directory and adds the salary information. The
  player directory contains 1,011 players, of which 111 are goalies.
\item
  The file \texttt{salary\_fill.py} contains code for filling in some
  missing salary information that was not immediately available from
  CapFriendly. 25 players did not have 2015-2016 salaries available, so
  I used their 2016-2017 salaries. Salaries are only being used to
  estimate perception of player quality, so using salary from two
  different years is not such a big deal.
\item
  The file \texttt{report\_downloader.py} contains code for downloading
  the play-by-play and event summary reports. I used this because I
  wanted to work on scraping while off-line.
\item
  Besides salary information, I also wanted to use time-on-ice (TOI)
  information. The file \texttt{es\_scrape.py} includes code for doing
  this. It includes a class \texttt{EventParse} that looks at the
  event-summary reports and extracts TOI for each player for each game,
  and a class \texttt{TOIBuilder} which totals season TOI and adds it to
  the player directory. It also includes a function
  \texttt{Dir\_process} which adds a column \texttt{paTOI/G} to the
  directory. This statistic is the per-game TOI for each player,
  multiplied by 0.75 if the player is a defenseman. Because there are 3
  defense lines to 4 forward lines, defensemen play approximately 4/3 as
  much, so TOI/G should be adjusted.
\item
  The file \texttt{attempt\_scrape.py} contains code for extracting the
  shot-attempt data for each game and saving it as a table. These tables
  include 14 columns: the event type (shot, missed shot, goal, blocked shot),
  a boolean stating whether the attempt was for the home team, the
  jersey numbers for the six home players and six away players (some of
  which would be listed as \texttt{None} if there were penalties).
\end{enumerate}

There is more work to be done. In a separate folder, I have
code for wrangling:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wrangling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

            \begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} ['attempt\_manager.py',
         'data\_split.py',
         'summary\_manager.py',
         '\_\_init\_\_.py']
\end{Verbatim}
        
    I'll talk about \texttt{data\_split.py} in a bit. The other two files:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{attempt\_manager.py} is responsible for consolidating the
  shot-attempt data into one data set. It contains a class
  \texttt{attempt\_manager} that does this. It saves a number of objects
  into the file \texttt{Attempts.npz}. First and foremost, it contains a
  0-1 sparse matrix (a \texttt{csc\_matrix} object from the module
  \texttt{scipy.sparse}) with 1800 columns and 136,530 rows. Each row
  represents one shot attempt, and each column represents one player,
  and each element is \texttt{True} if and only if that player was on
  the ice for that shot attempt. There are 1800 columns because there
  are 900 players (we exclude the goalies) and we consider a player
  at-home to be distinct from a player away-from-home, so columns 1-900
  are home players and 901-1800 away players.

  The sparse matrix is our main data set, but some other objects are
  also contained in the file:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    the list of non-goalie names so that we can match the columns to
    players.
  \item
    game counts: the number of shot attempts in each game.
  \item
    a list of indices indicating which of the shot attempts was for the
    home team. This is our indicator variable.
  \item
    a list of attempt types (whether an attempt was a goal, shot, missed
    shot, or blocked shot).
  \item
    four lists indicating the average salary and average playing time of
    the players on-ice for the home and away sides.
  \end{itemize}

  The class also contains a method \texttt{compute\_Corsi} which
  computes the season CF for any player.
\item
  The file \texttt{summary\_manager.py} is for looking at attempt data
  on a game-by-game basis. It includes a class \texttt{summary\_manager}
  which adds the goals, shots, missed shots, blocked shots and total
  shot attempts for each team in each game and saves it in the file
  \texttt{Summary.csv} as a 1230 by 10 table.
\end{enumerate}

    \section{A first look at the data}\label{a-first-look-at-the-data}

    Two proxy statistics we can use to assess `quality of opponent' (or at
least the perception of quality) are player salary and player playing
time. Salary is a little problematic, because younger players are
certainly underpaid, and the production of older players can fall off
after getting a fat contract. The latter statistic is probably better,
because a coach can respond quickly to changes in playing quality, and
because there is a decent spread in player time-on-ice (TOI):

    \begin{Verbatim}[commandchars=\\\{\}]
        
{\color{incolor}In [{\color{incolor}17}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline        
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}

	 \PY{n}{players} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/Directory.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{players} \PY{o}{=} \PY{n}{players}\PY{p}{[} \PY{o}{\PYZti{}}\PY{n}{players}\PY{o}{.}\PY{n}{TOI}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{p}{]}
         \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(} \PY{n+nb}{list}\PY{p}{(}\PY{n}{players}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{paTOI/G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Positionally adjusted minutes on\PYZhy{}ice per game}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_9_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
\noindent There is a good variation in this statistic, and it is likely that `better' players will have higer playing time (PT), as coaches pay close attention to this statistic on a game-by-game basis.

Now, let us show the raw numbers for shot attempts and players:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{import} \PY{n+nn}{wrangling.attempt\PYZus{}manager} \PY{k+kn}{as} \PY{n+nn}{am}
         
         \PY{n}{AM} \PY{o}{=} \PY{n}{am}\PY{o}{.}\PY{n}{attempt\PYZus{}manager}\PY{p}{(}\PY{p}{)}
         \PY{n}{AM}\PY{o}{.}\PY{n}{Load}\PY{p}{(}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of non\PYZhy{}goalies that dressed in 2015\PYZhy{}16: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
		\PY{n+nb}{len}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{NGs}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{t\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Goals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shots saved}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shot missed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shots blocked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{k} \PY{o+ow}{in} \PY{n}{t\PYZus{}dict}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{k}{print} \PY{n}{t\PYZus{}dict}\PY{p}{[}\PY{n}{k}\PY{p}{]} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{attempt\PYZus{}type}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{n}{k}\PY{p}{)}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Total shot attempts: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(} \PY{n}{AM}\PY{o}{.}\PY{n}{no\PYZus{}att} \PY{p}{)} 
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of non-goalies that dressed in 2015-16: 900
Shots saved: 66601
Shots blocked: 34845
Shot missed: 28519
Goals: 6565
Total shot attempts: 136530

    \end{Verbatim}

    We can see there is a home-ice advantage:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Home goals: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(} \PY{n+nb}{sum}\PY{p}{(} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(} \PY{n}{AM}\PY{o}{.}\PY{n}{attempt\PYZus{}type}\PY{p}{) \textbackslash }
		\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Away goals: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{attempt\PYZus{}type}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{sum}\PY{p}{( \textbackslash} 
		\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(} \PY{n}{AM}\PY{o}{.}\PY{n}{attempt\PYZus{}type}\PY{p}{)}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{p}{)}\PY{p}{)}
         
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Home shot attempts: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{)}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Away shot attempts: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(} \PY{n}{AM}\PY{o}{.}\PY{n}{no\PYZus{}att} \PY{o}{\PYZhy{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{)} \PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Home goals: 3404
Away goals: 3161
Home shot attempts: 70468
Away shot attempts: 66062

    \end{Verbatim}

    If playing time and salary are both good measures of player quality, we
should expect them to correlate:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{players}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{paTOI/G}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{players}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Salary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{24}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Positionally adjusted TOI per game}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Annual salary in tens of millions of USD}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_15_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We see a clear correlation, although we can see a subgroup that is
rather flat at the bottom. As it happens, entry-level contracts are
capped at 925,000 USD, so that subgroup represents the underpaid young
players.

    To support our claim that better players tend to share the ice with
other better players, we consider the average salary and playing time
for home players versus away players. \texttt{attempt\_manager} has
class variables recording this data.

Visually it's difficult to tell whether there's a good correlation,
especially with respect to salary:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{h\PYZus{}sal} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}sal}\PY{p}{)}
         \PY{n}{a\PYZus{}sal} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}sal}\PY{p}{)}
         \PY{n}{h\PYZus{}PT} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}
         \PY{n}{a\PYZus{}PT} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{h\PYZus{}sal}\PY{p}{,}\PY{n}{a\PYZus{}sal}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. home salary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. away salary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{h\PYZus{}PT}\PY{p}{,}\PY{n}{a\PYZus{}PT}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. home PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. away PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    If we run a linear regression however, we can see that, after proper
scaling, there is a moderate salary correlation:

    \begin{Verbatim}[commandchars=\\\{\}]
        

{\color{incolor}In [{\color{incolor}16}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LinearRegression}\PY{p}{,} \PY{n}{LogisticRegression}
	 \PY{n}{h\PYZus{}sal\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{h\PYZus{}sal}\PY{o}{\PYZhy{}}\PY{n}{h\PYZus{}sal}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{n}{h\PYZus{}sal}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
         \PY{n}{a\PYZus{}sal\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{a\PYZus{}sal}\PY{o}{\PYZhy{}}\PY{n}{a\PYZus{}sal}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{n}{a\PYZus{}sal}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{LR} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{LR}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{h\PYZus{}sal\PYZus{}norm}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{a\PYZus{}sal\PYZus{}norm}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{k}{print} \PY{n}{LR}\PY{o}{.}\PY{n}{intercept\PYZus{}}\PY{p}{,} \PY{n}{LR}\PY{o}{.}\PY{n}{coef\PYZus{}}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[  1.27271388e-14] [[ 0.14216014]]

    \end{Verbatim}

    And when we do the same to the playing time data, we get a correlation
coefficient of 0.30. This is around what I would expect: a definite
correlation, but enough `cross-talk' between various lines that we get
good players on the ice with not-so-good players at a reasonable clip.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{h\PYZus{}PT\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{h\PYZus{}PT}\PY{o}{\PYZhy{}}\PY{n}{h\PYZus{}PT}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{n}{h\PYZus{}PT}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
         \PY{n}{a\PYZus{}PT\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{a\PYZus{}PT}\PY{o}{\PYZhy{}}\PY{n}{a\PYZus{}PT}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{n}{a\PYZus{}PT}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{LR} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{LR}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{h\PYZus{}PT\PYZus{}norm}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{a\PYZus{}PT\PYZus{}norm}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{k}{print} \PY{n}{LR}\PY{o}{.}\PY{n}{intercept\PYZus{}}\PY{p}{,} \PY{n}{LR}\PY{o}{.}\PY{n}{coef\PYZus{}}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[ -3.04233575e-14] [[ 0.29567157]]

    \end{Verbatim}

    We can now ask whether these two metrics affect shot attempts:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{away\PYZus{}indices} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{attempt\PYZus{}type}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{p}{\textbackslash} 
		\PY{n+nb}{set}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{)}\PY{p}{)}
         \PY{n}{away\PYZus{}indices}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff\PYZus{}home} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]}\PY{o}{\PYZhy{}} \PY{p}{\textbackslash} 
		\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff\PYZus{}away} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{p}{\textbackslash}
		 \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]}\PY{p}{)}
         \PY{n}{PT\PYZus{}diff\PYZus{}home} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{p}{\textbackslash}
		 \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]}
         \PY{n}{PT\PYZus{}diff\PYZus{}away} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{p}{\textbackslash}
		 \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{p}{[}\PY{n}{sal\PYZus{}diff\PYZus{}home}\PY{p}{,}\PY{n}{sal\PYZus{}diff\PYZus{}away}\PY{p}{]}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{p}{[}\PY{n}{PT\PYZus{}diff\PYZus{}home}\PY{p}{,}\PY{n}{PT\PYZus{}diff\PYZus{}away}\PY{p}{]}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. salary difference}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Avg. PT difference}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{:}
             \PY{n}{ax}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}xticklabels}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Home}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Away}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_24_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    It is clear that effect size is actually quite small, and in the case of
salary, there may not be any effect at all. Despite the very significant
overlap in both cases, our sample size is very large, so we may get very
large z-statistics anyway.

    \begin{Verbatim}[commandchars=\\\{\}]
        

{\color{incolor}In [{\color{incolor}21}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
	 \PY{k+kn}{import} \PY{n+nn}{scipy.stats} \PY{k+kn}{as} \PY{n+nn}{sps} 

	 \PY{n}{sal\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}home}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{} \textbackslash} 
	 	\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}away}\PY{p}{)}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}home}\PY{p}{)}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff\PYZus{}var\PYZus{}away} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}away}\PY{p}{)}\PY{p}{)}
         \PY{n}{nh} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}home}\PY{p}{)}
         \PY{n}{na} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}away}\PY{p}{)}
         \PY{n}{sal\PYZus{}diff\PYZus{}error} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{l+m+mi}{1}\PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n}{na}\PY{p}{)}\PY{p}{)} \PY{o}{* \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{p}{(}\PY{n}{nh}\PY{o}{*}\PY{n}{sal\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{+} \PY{n}{nh}\PY{o}{*}\PY{n}{sal\PYZus{}diff\PYZus{}var\PYZus{}away}\PY{p}{)}\PY{o}{/ \textbackslash} 
		\PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{o}{+}\PY{n}{na}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{z\PYZus{}statistic} \PY{o}{=} \PY{n}{sal\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{/} \PY{n}{sal\PYZus{}diff\PYZus{}error}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Difference in salary discrepancy between \textbackslash}
	 \PY{l+s+s1}{home and away SA: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{sal\PYZus{}diff\PYZus{}mean\PYZus{}diff}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The z\PYZhy{}score is: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The probability that this is just a fluke is: \textbackslash}
	 \PY{l+s+s1}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{sps}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Difference in salary discrepancy between home and away SA: 426308.743591
The z-score is: 44.9592485704
The probability that this is just a fluke is: 0.0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{PT\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}home}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{} \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}away}\PY{p}{)}\PY{p}{)}
         \PY{n}{PT\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}home}\PY{p}{)}\PY{p}{)}
         \PY{n}{PT\PYZus{}diff\PYZus{}var\PYZus{}away} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}away}\PY{p}{)}\PY{p}{)}
         \PY{n}{nh} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}home}\PY{p}{)}
         \PY{n}{na} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}away}\PY{p}{)}
         \PY{n}{PT\PYZus{}diff\PYZus{}error} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{l+m+mi}{1}\PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n}{na}\PY{p}{)}\PY{p}{)} \PY{o}{* \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{p}{(}\PY{n}{nh}\PY{o}{*}\PY{n}{PT\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{+} \PY{n}{nh}\PY{o}{*}\PY{n}{PT\PYZus{}diff\PYZus{}var\PYZus{}away}\PY{p}{)}\PY{o}{/  \textbackslash} 
		\PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{o}{+}\PY{n}{na}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{z\PYZus{}statistic} \PY{o}{=} \PY{n}{PT\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{/} \PY{n}{PT\PYZus{}diff\PYZus{}error}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Difference in playing time discrepancy between home  \textbackslash}
	 \PY{l+s+s1}{and away SA: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{PT\PYZus{}diff\PYZus{}mean\PYZus{}diff}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The z\PYZhy{}score is: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The probability that this is just a fluke is: \textbackslash}
	 \PY{l+s+s1}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{sps}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Difference in playing time discrepancy between home and away SA: 0.665294931899
The z-score is: 57.9543230745
The probability that this is just a fluke is: 0.0

    \end{Verbatim}

    Both of the effect sizes (average salary bump of \$436,000 and playing
time bump of 36 seconds per 60 minutes) are rather small but definitely
not trivial. Additionally, the large sample sizes allow us to conclude
that these effects are very significant. If salary and playing time are
good indicators of player ability, then the ability of players on the
ice affects frequency of shot attempts.

    We have already mentioned that playing time is probably a better
indicator of player ability than salary. Moreover, both variables are
correlated, so is it necessary to consider both? More variables lead to
overfitting and we don't want two features when only one is needed.

Now, one can imagine reasons why salary could still be useful. Some
older players may be quite skilled but with lower stamina. Therefore
they may be well compensated, but given less playing time. A more
important effect is that players on bad teams get more playing time than
they deserve, because their competition is limited. Presumably their
salary would not reflect this lower competition. Conversely, players on
loaded teams may be well-paid to reflect their ability, but may see less
ice-team because their teammates are good. This effect is probably
mitigated considerably by the salary cap, but let us examine the data.

Let's create a third feature by projecting away PT from the salary data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{numerator1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{T \textbackslash} 
		\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{denom1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{T} \PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{adj\PYZus{}sal\PYZus{}home} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}sal}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{numerator1}\PY{o}{/}\PY{n}{denom1} \PY{o}{* \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}OI\PYZus{}PT}\PY{p}{)}
         
         \PY{n}{numerator2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}sal}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{T \textbackslash} 
		\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{denom2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}\PY{o}{.}\PY{n}{T} \PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{adj\PYZus{}sal\PYZus{}away} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}sal}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{numerator2}\PY{o}{/}\PY{n}{denom2} \PY{o}{* \textbackslash}
		 \PY{n}{np}\PY{o}{.}\PY{n}{matrix}\PY{p}{(}\PY{n}{AM}\PY{o}{.}\PY{n}{away\PYZus{}OI\PYZus{}PT}\PY{p}{)}
         
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}home} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}home}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]} \PY{o}{\PYZhy{} \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}away}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{AM}\PY{o}{.}\PY{n}{home\PYZus{}indices}\PY{p}{]}
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}away} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}home}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]} \PY{o}{\PYZhy{} \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}away}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{away\PYZus{}indices}\PY{p}{]}
         
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}home}\PY{p}{)} \PY{o}{\PYZhy{} \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}away}\PY{p}{)}
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}home}\PY{p}{)}
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}var\PYZus{}away} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}away}\PY{p}{)}
         \PY{n}{nh} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}home}\PY{p}{)}
         \PY{n}{na} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}away}\PY{p}{)}
         \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}error} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{l+m+mi}{1}\PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n}{na}\PY{p}{)}\PY{p}{)} \PY{o}{* \textbackslash} 
		\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{p}{(}\PY{n}{nh}\PY{o}{*}\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}var\PYZus{}home} \PY{o}{+} \PY{n}{nh}\PY{o}{* \textbackslash}
		\PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}var\PYZus{}away}\PY{p}{)}\PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{nh}\PY{o}{+}\PY{n}{na}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{z\PYZus{}statistic} \PY{o}{=} \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}mean\PYZus{}diff} \PY{o}{/} \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}error}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Difference in adjusted salary discrepancy between home and \textbackslash}
	 \PY{l+s+s1}{away SA: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(} \PY{n}{adj\PYZus{}sal\PYZus{}diff\PYZus{}mean\PYZus{}diff}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The z\PYZhy{}score is: \PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}
         \PY{k}{print} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The probability that this is just a fluke is: \textbackslash}
	 \PY{l+s+s1}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{sps}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{z\PYZus{}statistic}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Difference in adjusted salary discrepancy between home and away SA: 285534.784257
The z-score is: 34.9461561288
The probability that this is just a fluke is: 0.0

    \end{Verbatim}

    So, the adjustment decreases the effect size, by slightly less than
half. Yet the confidence in a significant result is still extremely
high. The large sample size has lot to do with this, but as of now, the
data indicates we should keep both variables.

    \section{Basic models}\label{basic-models}

    The first step is to use a logistic regression. We will look at three
simple models:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A logistic regression that just uses the Corsi numbers of the home and
  away players. The correct features are not the CF\% numbers
  themselves, but the log-likelihoods thereof. Additionally, we are not going
  to use the \emph{averages}, but the sum. The reason for this is that power play
  situations mean that the number of players on-ice is not constant,
  and this certainly affects the shot attempts. Therefore, our first two
  variables are $x_1 = \sum_{i, X_i \textrm{ on-ice }} \log(LCF\%(X_i))$
  and $x_2 = \sum_{i, Y_i \textrm{ on-ice }} \log(LCF\%(Y_i))$, where
  $X_i$ and $Y_i$ represent home and away players, respectively, and $LCF\%$ indicates $\frac{CF\%}{1-CF\%}$.
\item
  A logistic regression that adds two more variables: $x_3$ and $x_4$,
  the average playing-time of the home on-ice players and the away
  on-ice players.
\item
  A logistic regression that adds another two variables: $x_5$ and
  $x_6$, the average salary of the home on-ice players and the away
  on-ice players.
\end{enumerate}

First, to properly evaluate our models, we need to make a training /
cross-validation split. We have some code in the file
\texttt{data\_split.py} that does this. Sixty percent of our data set is
sent to the file \texttt{Training.npz} to be use to train our algorithm.
The split is done randomly (and seeded properly). The remaining data are
split evenly and sent to \texttt{CPV.npz} and \texttt{Test.npz}.

After we obtain our training set, we must reduce our data set to the six
desired features. We have code in the file \texttt{feature\_assemble.py}
that accomplishes this. It contains a class \texttt{FeatureAssemble},
which includes methods \texttt{Corsis()} and \texttt{Assemble()}. The
former computes the CF\% stats, but only using the shot attempts in the
training set, and the latter constructs a table containing $x_1$ through
$x_6$.

One practical issue that should be noted: since we are using
log-likelihoods, any CF\% that is 0 or 100 will cause an error. This is
not an issue for most players, but for players that have little data
available, we must use a fudge factor $\epsilon$, and insist that every
player is on the ice for at least $\epsilon$ shot attempts in either
direction. In our code we use $\epsilon=0.1$, so that a player that is
on the ice for only one shot attempt has a $CF\%$ of either 9.09\% or
90.9\%. This also means a player who sees zero shot attempts has a CF\%
of exactly 50\%.

Now that we have constructed our data, we code a logistic classifier
object \texttt{small\_logistic}, contained in the file
\texttt{small\_logistic.py}. This object first scales the data (this is
important, as salary is much larger in scale than playing time), and
then fits the data three times. First using only $x_1$ and $x_2$, second
adding $x_3$ and $x_4$, and third adding $x_5$ and $x_6$. It can also
compute the prediction score and cross-entropy of the trained classifier
on both the training and cross-validation data. We use another object
called \texttt{SL\_sweeper} that varies the regularization strength
(actually the parameter is $C$, the inverse of the regularization
strength):

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{import} \PY{n+nn}{small\PYZus{}logistic.small\PYZus{}logistic} \PY{k+kn}{as} \PY{n+nn}{slr}
        
        \PY{n}{C} \PY{o}{=} \PY{p}{[} \PY{n+nb}{pow}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{c}\PY{o}{/}\PY{l+m+mf}{2.}\PY{p}{)} \PY{k}{for} \PY{n}{c} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{]}
        \PY{n}{SLS} \PY{o}{=} \PY{n}{slr}\PY{o}{.}\PY{n}{SL\PYZus{}sweeper}\PY{p}{(}\PY{n}{C}\PY{p}{)}
        \PY{n}{SLS}\PY{o}{.}\PY{n}{training}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

Now that we have trained the algorithm, we can display the learning
curves. The four graphs below show the prediction score (left) and
cross-entropy (right) as $C$ varies, for all three methods. The lower
graphs are identical to upper graphs, but with the vertical scale
magnified, so that we can see the separation of the three algorithms:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}82}]:} \PY{n}{fig2}\PY{p}{,} \PY{n}{ax2} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2} \PY{p}{)}
         
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi only}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi + PT}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{,} \PY{n}{label}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi + PT + salary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{.}\PY{l+m+mi}{6135}\PY{p}{,}\PY{o}{.}\PY{l+m+mi}{6155}\PY{p}{]}\PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
         \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{.}\PY{l+m+mi}{651}\PY{p}{,}\PY{o}{.}\PY{l+m+mi}{654}\PY{p}{]}\PY{p}{)}
         \PY{n}{h}\PY{p}{,} \PY{n}{l} \PY{o}{=} \PY{n}{ax2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{get\PYZus{}legend\PYZus{}handles\PYZus{}labels}\PY{p}{(}\PY{p}{)}
         \PY{n}{fig2}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{h}\PY{p}{,}\PY{n}{l}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{1.4}\PY{p}{,}\PY{l+m+mf}{0.6}\PY{p}{)} \PY{p}{)}
         \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{:}
             \PY{n}{ax2}\PY{p}{[}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Prediction score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{ax2}\PY{p}{[}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross\PYZhy{}entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{fig2}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{o}{.}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Negative log of regularization strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{fig2}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of algorithms on training data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+m+mf}{1.1}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_36_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Here is how the algorithms fare on the cross-validation data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}104}]:} \PY{n}{fig3}\PY{p}{,} \PY{n}{ax3} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi only}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi + PT}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{,} \PY{n}{label}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsi + PT + salary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scores}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{.}\PY{l+m+mi}{62}\PY{p}{,}\PY{o}{.}\PY{l+m+mi}{63}\PY{p}{]}\PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Corsis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{plus\PYZus{}PT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{C}\PY{p}{)}\PY{p}{,} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
          \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{.}\PY{l+m+mi}{64}\PY{p}{,}\PY{o}{.}\PY{l+m+mi}{642}\PY{p}{]}\PY{p}{)}
          \PY{n}{h}\PY{p}{,} \PY{n}{l} \PY{o}{=} \PY{n}{ax3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{get\PYZus{}legend\PYZus{}handles\PYZus{}labels}\PY{p}{(}\PY{p}{)}
          \PY{n}{fig3}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{h}\PY{p}{,}\PY{n}{l}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{1.4}\PY{p}{,}\PY{l+m+mf}{0.6}\PY{p}{)} \PY{p}{)}
          \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{:}
              \PY{n}{ax3}\PY{p}{[}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Prediction score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax3}\PY{p}{[}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross\PYZhy{}entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{fig3}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{o}{.}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Negative log of regularization strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{fig3}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of algorithms on cross\PYZhy{}validation data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
		\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+m+mf}{1.1}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{MilestoneReport_files/MilestoneReport_38_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    If we pick the algorithm that performs best, and choose the best $C$,
these are our performance metrics:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}105}]:} \PY{n}{best\PYZus{}C} \PY{o}{=} \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cross entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{argmin}\PY{p}{(}\PY{p}{)}
          \PY{n}{SLS}\PY{o}{.}\PY{n}{eval\PYZus{}matrix}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{best\PYZus{}C}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}

            \begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}105}]:} split     metric       
          Training  Scores           0.6145658
                    Cross entropy    0.6518095
          CV        Scores           0.6280305
                    Cross entropy    0.6405135
          Name: 3162.27766017, dtype: object
\end{Verbatim}
        
    Some observations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  We must admit that the improvement we get by adding salary and PT is
  very small (so small that we needed to magnify). Ultimately, this has
  to be somewhat disappointing.
\item
  The prediction score using just the Corsi numbers however is not that
  bad. This is an inherently noisy process, so we do not expect do get
  anywhere near to even 90\% prediction score. Getting above 60\% is
  rather satisfying. Clearly, we have some predictive power.
\item
  Judging by cross-entropy on the training and cross-validation sets,
  adding PT improves our model, and adding salary improves it even more.
  Interestingly, these improvements do not necessarily carry over to the
  prediction score. Adding salary hurts the prediction score on the
  training set, while on the cross-validation set, the Corsi + PT model
  performs the worst! Ultimately, we have to judge our model on
  cross-entropy rather than prediction score.
\item
  Strangely, our metrics are slightly better on the cross-validation
  data! Presumably, this is because of a smaller data set (although of
  course we are using average cross-entropy).
\item
  The cross-validation learning curves do not really show an optimum:
  the performance does not suffer by eliminating regularization.
\end{enumerate}

We can conclude from 4. and 5. that we are definitely not over-fitting
our algorithms. Combining that with the disappointing improvement
indicates we need to implement more powerful models.

    \section{The next steps}\label{the-next-steps}

    The models described so far are quite basic, and more sophistication is
required. I intend to do use two more algorithms to improve my
predictions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A force-equilibrium model. Assume that player $j$ has an adjusted
  Corsi likelihood $r_j$, and let $S_{jk}$ be the number of shot
  attempts for player $k$'s team while players $j$ and $k$ are on the
  ice against each other. Imagine this data exerts a ``force'' on $r_j$
  proportional to the shot attempt numbers that adjusts the likelihoods
  in the proper direction. This sets up a set of differential equations:

  \begin{align}
  \frac{dr_j}{dt} &= -S_{kj}r_j + \sum_{k\ne j}  S_{jk}r_k
  \end{align}

  We then adjust $r_j$ to be the equilibrium solution of these equations
  (i.e.~all forces are zero). This is inspired by the principle of
  detailed balance that Einstein used to describe quantum emission and
  absorption of photons.

  For example, if there are only two players, the solution (up to a
  multiplicative constant) is $r_1 = \frac{S_{21}}{S_{12}}$ and
  $r_2=\frac{1}{r_1}$. This is clearly the most parsimonious approach: the
  corresponding probability would be $\frac{S_{12}}{S_{12}+S_{21}}$ and
  $\frac{S_{21}}{S_{12}+S_{21}}$, which of course are the usual CF
  numbers.

  But let us add a third player. Suppose players 1 and 2 play each other
  and there are five shot attempts for each team. Then players 1 and 3 play
  each other and there are nine shot attempts for player 1's team and
  one for player 3's team. The CF percentages end up being 70\%, 50\%
  and 10\%. However, the numbers indicate that players 1 and 2 should be considered equal.
  If we feed these numbers into the differential equations above and
  solve, we get $r_1 = r_2 = \frac{27}{19}$ and $r_3 = \frac{3}{19}$.
  This is leads to probabilities 58.7\%, 58.7\% and 13.6\%, which appear
  to be more sensible.

  Once I have computed these likelihoods $r_j$, I can use them in a new
  logistic regression model to predict shot attempts on the
  cross-validation set.
\item
  Logistic regression and possibly neural networks on the entire
  training set. Instead of using six features as above, I can use all
  1800 features that exist in the data set. With this many features,
  over-fitting is a concern, so attention must be given to the learning
  curves.
\end{enumerate}

    
    
    \end{document}
